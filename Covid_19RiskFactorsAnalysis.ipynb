{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>Microsoft Academic Paper ID</th>\n",
       "      <th>WHO #Covidence</th>\n",
       "      <th>has_pdf_parse</th>\n",
       "      <th>has_pmc_xml_parse</th>\n",
       "      <th>full_text_file</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xqhn0vbp</td>\n",
       "      <td>1e1286db212100993d03cc22374b624f7caee956</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Airborne rhinovirus detection and effect of ul...</td>\n",
       "      <td>10.1186/1471-2458-3-5</td>\n",
       "      <td>PMC140314</td>\n",
       "      <td>12525263.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>BACKGROUND: Rhinovirus, the most common cause ...</td>\n",
       "      <td>2003-01-13</td>\n",
       "      <td>Myatt, Theodore A; Johnston, Sebastian L; Rudn...</td>\n",
       "      <td>BMC Public Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>gi6uaa83</td>\n",
       "      <td>8ae137c8da1607b3a8e4c946c07ca8bda67f88ac</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Discovering human history from stomach bacteria</td>\n",
       "      <td>10.1186/gb-2003-4-5-213</td>\n",
       "      <td>PMC156578</td>\n",
       "      <td>12734001.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Recent analyses of human pathogens have reveal...</td>\n",
       "      <td>2003-04-28</td>\n",
       "      <td>Disotell, Todd R</td>\n",
       "      <td>Genome Biol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>le0ogx1s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PMC</td>\n",
       "      <td>A new recruit for the army of the men of death</td>\n",
       "      <td>10.1186/gb-2003-4-7-113</td>\n",
       "      <td>PMC193621</td>\n",
       "      <td>12844350.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>The army of the men of death, in John Bunyan's...</td>\n",
       "      <td>2003-06-27</td>\n",
       "      <td>Petsko, Gregory A</td>\n",
       "      <td>Genome Biol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fy4w7xz8</td>\n",
       "      <td>0104f6ceccf92ae8567a0102f89cbb976969a774</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Association of HLA class I with severe acute r...</td>\n",
       "      <td>10.1186/1471-2350-4-9</td>\n",
       "      <td>PMC212558</td>\n",
       "      <td>12969506.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>BACKGROUND: The human leukocyte antigen (HLA) ...</td>\n",
       "      <td>2003-09-12</td>\n",
       "      <td>Lin, Marie; Tseng, Hsiang-Kuang; Trejaut, Jean...</td>\n",
       "      <td>BMC Med Genet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0qaoam29</td>\n",
       "      <td>5b68a553a7cbbea13472721cd1ad617d42b40c26</td>\n",
       "      <td>PMC</td>\n",
       "      <td>A double epidemic model for the SARS propagation</td>\n",
       "      <td>10.1186/1471-2334-3-19</td>\n",
       "      <td>PMC222908</td>\n",
       "      <td>12964944.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>BACKGROUND: An epidemic of a Severe Acute Resp...</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>Ng, Tuen Wai; Turinici, Gabriel; Danchin, Antoine</td>\n",
       "      <td>BMC Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       sha source_x  \\\n",
       "0  xqhn0vbp  1e1286db212100993d03cc22374b624f7caee956      PMC   \n",
       "1  gi6uaa83  8ae137c8da1607b3a8e4c946c07ca8bda67f88ac      PMC   \n",
       "2  le0ogx1s                                       NaN      PMC   \n",
       "3  fy4w7xz8  0104f6ceccf92ae8567a0102f89cbb976969a774      PMC   \n",
       "4  0qaoam29  5b68a553a7cbbea13472721cd1ad617d42b40c26      PMC   \n",
       "\n",
       "                                               title                      doi  \\\n",
       "0  Airborne rhinovirus detection and effect of ul...    10.1186/1471-2458-3-5   \n",
       "1    Discovering human history from stomach bacteria  10.1186/gb-2003-4-5-213   \n",
       "2     A new recruit for the army of the men of death  10.1186/gb-2003-4-7-113   \n",
       "3  Association of HLA class I with severe acute r...    10.1186/1471-2350-4-9   \n",
       "4   A double epidemic model for the SARS propagation   10.1186/1471-2334-3-19   \n",
       "\n",
       "       pmcid   pubmed_id license  \\\n",
       "0  PMC140314  12525263.0   no-cc   \n",
       "1  PMC156578  12734001.0   no-cc   \n",
       "2  PMC193621  12844350.0   no-cc   \n",
       "3  PMC212558  12969506.0   no-cc   \n",
       "4  PMC222908  12964944.0   no-cc   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  BACKGROUND: Rhinovirus, the most common cause ...   2003-01-13   \n",
       "1  Recent analyses of human pathogens have reveal...   2003-04-28   \n",
       "2  The army of the men of death, in John Bunyan's...   2003-06-27   \n",
       "3  BACKGROUND: The human leukocyte antigen (HLA) ...   2003-09-12   \n",
       "4  BACKGROUND: An epidemic of a Severe Acute Resp...   2003-09-10   \n",
       "\n",
       "                                             authors            journal  \\\n",
       "0  Myatt, Theodore A; Johnston, Sebastian L; Rudn...  BMC Public Health   \n",
       "1                                   Disotell, Todd R        Genome Biol   \n",
       "2                                  Petsko, Gregory A        Genome Biol   \n",
       "3  Lin, Marie; Tseng, Hsiang-Kuang; Trejaut, Jean...      BMC Med Genet   \n",
       "4  Ng, Tuen Wai; Turinici, Gabriel; Danchin, Antoine     BMC Infect Dis   \n",
       "\n",
       "   Microsoft Academic Paper ID WHO #Covidence  has_pdf_parse  \\\n",
       "0                          NaN            NaN           True   \n",
       "1                          NaN            NaN           True   \n",
       "2                          NaN            NaN          False   \n",
       "3                          NaN            NaN           True   \n",
       "4                          NaN            NaN           True   \n",
       "\n",
       "   has_pmc_xml_parse  full_text_file  \\\n",
       "0               True  custom_license   \n",
       "1               True  custom_license   \n",
       "2               True  custom_license   \n",
       "3               True  custom_license   \n",
       "4               True  custom_license   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...  \n",
       "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...  \n",
       "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...  \n",
       "3  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...  \n",
       "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('metadata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52398 entries, 0 to 52397\n",
      "Data columns (total 18 columns):\n",
      "cord_uid                       52398 non-null object\n",
      "sha                            39024 non-null object\n",
      "source_x                       52398 non-null object\n",
      "title                          52240 non-null object\n",
      "doi                            49058 non-null object\n",
      "pmcid                          43652 non-null object\n",
      "pubmed_id                      38058 non-null float64\n",
      "license                        52398 non-null object\n",
      "abstract                       43168 non-null object\n",
      "publish_time                   52390 non-null object\n",
      "authors                        50119 non-null object\n",
      "journal                        47156 non-null object\n",
      "Microsoft Academic Paper ID    964 non-null float64\n",
      "WHO #Covidence                 1768 non-null object\n",
      "has_pdf_parse                  52398 non-null bool\n",
      "has_pmc_xml_parse              52398 non-null bool\n",
      "full_text_file                 43794 non-null object\n",
      "url                            52096 non-null object\n",
      "dtypes: bool(2), float64(2), object(14)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cord_uid                           0\n",
       "sha                            13374\n",
       "source_x                           0\n",
       "title                            158\n",
       "doi                             3340\n",
       "pmcid                           8746\n",
       "pubmed_id                      14340\n",
       "license                            0\n",
       "abstract                        9230\n",
       "publish_time                       8\n",
       "authors                         2279\n",
       "journal                         5242\n",
       "Microsoft Academic Paper ID    51434\n",
       "WHO #Covidence                 50630\n",
       "has_pdf_parse                      0\n",
       "has_pmc_xml_parse                  0\n",
       "full_text_file                  8604\n",
       "url                              302\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new empty dictionary named abstracts with two keys: title & abstract.\n",
    "my_dict = dict(title = [], abstract = [])\n",
    "# Loop through df with iterrows() method that iterates over the rows of a df and returns the index of each row.\n",
    "# We want to iterate where the abstract and title are not nul values.\n",
    "for ind, row in df.iterrows():\n",
    "    if pd.notna(row['abstract']) and pd.notna(row['title']):\n",
    "        new_abstract = row['abstract'][0:250]\n",
    "        new_title = row['title'][0:250]\n",
    "        my_dict['title'].append(new_title)\n",
    "        my_dict['abstract'].append(new_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Airborne rhinovirus detection and effect of ul...</td>\n",
       "      <td>BACKGROUND: Rhinovirus, the most common cause ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Discovering human history from stomach bacteria</td>\n",
       "      <td>Recent analyses of human pathogens have reveal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A new recruit for the army of the men of death</td>\n",
       "      <td>The army of the men of death, in John Bunyan's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Association of HLA class I with severe acute r...</td>\n",
       "      <td>BACKGROUND: The human leukocyte antigen (HLA) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A double epidemic model for the SARS propagation</td>\n",
       "      <td>BACKGROUND: An epidemic of a Severe Acute Resp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Airborne rhinovirus detection and effect of ul...   \n",
       "1    Discovering human history from stomach bacteria   \n",
       "2     A new recruit for the army of the men of death   \n",
       "3  Association of HLA class I with severe acute r...   \n",
       "4   A double epidemic model for the SARS propagation   \n",
       "\n",
       "                                            abstract  \n",
       "0  BACKGROUND: Rhinovirus, the most common cause ...  \n",
       "1  Recent analyses of human pathogens have reveal...  \n",
       "2  The army of the men of death, in John Bunyan's...  \n",
       "3  BACKGROUND: The human leukocyte antigen (HLA) ...  \n",
       "4  BACKGROUND: An epidemic of a Severe Acute Resp...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new df from my_dict dictionary\n",
    "new_df = pd.DataFrame(my_dict)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Infectious Diseases                                                                                                                                                                                                                     9\n",
       "Abkürzungen                                                                                                                                                                                                                             5\n",
       "List of Abbreviations                                                                                                                                                                                                                   4\n",
       "Influenza                                                                                                                                                                                                                               4\n",
       "Appendix                                                                                                                                                                                                                                4\n",
       "                                                                                                                                                                                                                                       ..\n",
       "Chapter 6 Biology and Diseases of Guinea Pigs                                                                                                                                                                                           1\n",
       "Human brain evolution and the “Neuroevolutionary Time-depth Principle:” Implications for the Reclassification of fear-circuitry-related traits in DSM-V and for studying resilience to warzone-related posttraumatic stress disorder    1\n",
       "Disease Outbreaks Caused by Emerging Paramyxoviruses of Bat Origin                                                                                                                                                                      1\n",
       "Viral respiratory infections in a nursing home: a six-month prospective study                                                                                                                                                           1\n",
       "The costs and consequences of methicillin-resistant Staphylococcus aureus infection treatments in Canada                                                                                                                                1\n",
       "Name: title, Length: 42686, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown                                                                                                                                                                                                                                                       189\n",
       "The third edition of the Handbook of Proteolytic Enzymes aims to be a comprehensive reference work for the enzymes that cleave proteins and peptides, and contains over 800 chapters. Each chapter is organized into sections describing the name and hist     14\n",
       "[Image: see text]                                                                                                                                                                                                                                               6\n",
       "After detection of the first confirmed cases of COVID-19 in Iran, the National Committee on COVID-19 Epidemiology in Ministry of Health and Medical Education was established. This Committee is official source of gathering, analyzing, and reporting th      5\n",
       "We have developed a reverse genetics system for the avian coronavirus infectious bronchitis virus (IBV) in which a full-length cDNA corresponding to the IBV genome is inserted into the vaccinia virus genome under the control of a T7 promoter sequence      4\n",
       "                                                                                                                                                                                                                                                             ... \n",
       "Outbreaks of the filoviruses, Ebola and Marburg, usually garner immense public attention, often with a sensationalist bent in the lay press, focused on the apparently mysterious origins of the outbreak and the high mortality rates. The scientific com      1\n",
       "Adaptation is an evolving long-term process during which a population of life forms adjusts to changes in its habitat and surrounding environments. Adaptation by the global community as a unit is vital to cope with the effects of increasing populatio      1\n",
       "BACKGROUND: Health Sciences students are exposed early to hospitals and to activities which increase their risk of acquiring infections. Infection control practices are geared towards reduction of occurrence and transmission of infectious diseases. O      1\n",
       "Adenoviral (Ad) vectors have emerged as a promising gene delivery platform for a variety of therapeutic and vaccine purposes during last two decades. However, the presence of preexisting Ad immunity and the rapid development of Ad vector immunity sti      1\n",
       "We have previously shown that the porcine alphaherpesvirus pseudorabies virus (PRV) efficiently interferes with phosphorylation of the eukaryotic translation initiation factor eIF2α. Inhibition of phosphorylation of eIF2α has been reported earlier fo      1\n",
       "Name: abstract, Length: 42680, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['abstract'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(data):\n",
    "    data = data.lower()\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in symbols:\n",
    "        data = data.replace(i, \" \")\n",
    "    #replace the comma seperately\n",
    "    data = data.replace(',', ' ')\n",
    "    return data\n",
    "\n",
    "def remove_apostraphe(data):\n",
    "    data = data.replace(\"'\", \"\")\n",
    "    return data\n",
    "\n",
    "def remove_numbers(data):\n",
    "    nums = \"0123456789\"\n",
    "    for i in nums:\n",
    "        data = data.replace(i, \"\")\n",
    "        return data\n",
    "\n",
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/thoashook/nltk_data'\n    - '/Users/thoashook/opt/anaconda3/nltk_data'\n    - '/Users/thoashook/opt/anaconda3/share/nltk_data'\n    - '/Users/thoashook/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/Users/thoashook/nltk_data'\n    - '/Users/thoashook/opt/anaconda3/nltk_data'\n    - '/Users/thoashook/opt/anaconda3/share/nltk_data'\n    - '/Users/thoashook/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dcb1ca4d886d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mworking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mworking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mworking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mworking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mworking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ca6923a9df5b>\u001b[0m in \u001b[0;36mremove_stop_words\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mnew_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/thoashook/nltk_data'\n    - '/Users/thoashook/opt/anaconda3/nltk_data'\n    - '/Users/thoashook/opt/anaconda3/share/nltk_data'\n    - '/Users/thoashook/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# clean and replace with cleaned words\n",
    "tf_dict = {}\n",
    "idf_count = {}\n",
    "for i, ab in df['abstract'].items():\n",
    "    if pd.notna(ab):\n",
    "        sent_dict = {}\n",
    "        working = ab\n",
    "        working = lower(working)\n",
    "        working = remove_stop_words(working)\n",
    "        working = remove_punctuation(working)\n",
    "        working = remove_numbers(working)\n",
    "        working = remove_apostraphe(working)\n",
    "        working = remove_stop_words(working)\n",
    "        tokens = working.split(' ')\n",
    "    \n",
    "        for word in tokens:\n",
    "            for inc in include_terms:\n",
    "                if inc in word:\n",
    "                    if word in sent_dict.keys():\n",
    "                        sent_dict[word] = sent_dict[word]+1\n",
    "                    else:\n",
    "                        sent_dict[word] = 1\n",
    "                        if word in idf_count.keys():\n",
    "                            idf_count[word] = idf_count[word]+1\n",
    "                        else:\n",
    "                            idf_count[word] = 1\n",
    "        tf_dict[i] = sent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
